{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Node:\n",
    "    def __init__(self, inputs=[]):\n",
    "        self.inputs = inputs\n",
    "        self.outputs = []\n",
    "\n",
    "        for n in self.inputs:\n",
    "            n.outputs.append(self)\n",
    "            # set 'self' node as inbound_nodes's outbound_nodes\n",
    "\n",
    "        self.value = None\n",
    "\n",
    "        self.gradients = {}\n",
    "        # keys are the inputs to this node, and their\n",
    "        # values are the partials of this node with \n",
    "        # respect to that input.\n",
    "        # \\partial{node}{input_i}\n",
    "        \n",
    "    def forward(self):\n",
    "        '''\n",
    "        Forward propagation. \n",
    "        Compute the output value vased on 'inbound_nodes' and store the \n",
    "        result in self.value\n",
    "        '''\n",
    "\n",
    "        raise NotImplemented\n",
    "        \n",
    "    def backward(self):\n",
    "\n",
    "        raise NotImplemented\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "class Input(Node):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        An Input node has no inbound nodes.\n",
    "        So no need to pass anything to the Node instantiator.\n",
    "        '''\n",
    "        Node.__init__(self)\n",
    "\n",
    "    def forward(self, value=None):\n",
    "        '''\n",
    "        Only input node is the node where the value may be passed\n",
    "        as an argument to forward().\n",
    "        All other node implementations should get the value of the \n",
    "        previous node from self.inbound_nodes\n",
    "        \n",
    "        Example: \n",
    "        val0: self.inbound_nodes[0].value\n",
    "        '''\n",
    "        if value is not None:\n",
    "            self.value = value\n",
    "            ## It's is input node, when need to forward, this node initiate self's value.\n",
    "\n",
    "        # Input subclass just holds a value, such as a data feature or a model parameter(weight/bias)\n",
    "        \n",
    "    def backward(self):\n",
    "        self.gradients = {self:0}\n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]\n",
    "            self.gradients[self] = grad_cost * 1\n",
    "            \n",
    "        # input N --> N1, N2\n",
    "        # \\partial L / \\partial N \n",
    "        # ==> \\partial L / \\partial N1 * \\ partial N1 / \\partial N        \n",
    "        \n",
    "\n",
    "        \n",
    "class Add(Node):\n",
    "    def __init__(self, *nodes):\n",
    "        Node.__init__(self, nodes)\n",
    "\n",
    "    def forward(self):\n",
    "        self.value = sum(map(lambda n: n.value, self.inputs))\n",
    "        ## when execute forward, this node caculate value as defined.\n",
    "\n",
    "        \n",
    "        \n",
    "class Linear(Node):\n",
    "    def __init__(self, nodes, weights, bias):\n",
    "        Node.__init__(self, [nodes, weights, bias])\n",
    "\n",
    "    def forward(self):\n",
    "        inputs = self.inputs[0].value\n",
    "        weights = self.inputs[1].value\n",
    "        bias = self.inputs[2].value\n",
    "\n",
    "        self.value = np.dot(inputs, weights) + bias\n",
    "        \n",
    "    def backward(self):\n",
    "\n",
    "        # initial a partial for each of the inbound_nodes.\n",
    "        self.gradients = {n: np.zeros_like(n.value) for n in self.inputs}\n",
    "\n",
    "        for n in self.outputs:\n",
    "            # Get the partial of the cost w.r.t this node.\n",
    "            grad_cost = n.gradients[self]\n",
    "\n",
    "            self.gradients[self.inputs[0]] = np.dot(grad_cost, self.inputs[1].value.T)\n",
    "            self.gradients[self.inputs[1]] = np.dot(self.inputs[0].value.T, grad_cost)\n",
    "            self.gradients[self.inputs[2]] = np.sum(grad_cost, axis=0, keepdims=False)\n",
    "\n",
    "        # WX + B / W ==> X\n",
    "        # WX + B / X ==> W        \n",
    "          \n",
    "        \n",
    "class Sigmoid(Node):\n",
    "    def __init__(self, node):\n",
    "        Node.__init__(self, [node])\n",
    "\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1./(1 + np.exp(-1 * x))\n",
    "\n",
    "    def forward(self):\n",
    "        self.x = self.inputs[0].value\n",
    "        self.value = self._sigmoid(self.x)\n",
    "\n",
    "    def backward(self):\n",
    "        self.partial = self._sigmoid(self.x) * (1 - self._sigmoid(self.x))\n",
    "        \n",
    "        # y = 1 / (1 + e^-x)\n",
    "        # y' = 1 / (1 + e^-x) (1 - 1 / (1 + e^-x))\n",
    "        \n",
    "        self.gradients = {n: np.zeros_like(n.value) for n in self.inputs}\n",
    "\n",
    "        for n in self.outputs:\n",
    "            grad_cost = n.gradients[self]  # Get the partial of the cost with respect to this node.\n",
    "\n",
    "            self.gradients[self.inputs[0]] = grad_cost * self.partial\n",
    "            # use * to keep all the dimension same!.\n",
    "        \n",
    "     \n",
    "    \n",
    "class MSE(Node):\n",
    "    def __init__(self, y, a):\n",
    "        Node.__init__(self, [y, a])\n",
    "\n",
    "\n",
    "    def forward(self):\n",
    "        y = self.inputs[0].value.reshape(-1, 1)\n",
    "        a = self.inputs[1].value.reshape(-1, 1)\n",
    "        assert(y.shape == a.shape)\n",
    "\n",
    "        self.m = self.inputs[0].value.shape[0]\n",
    "        self.diff = y - a\n",
    "\n",
    "        self.value = np.mean(self.diff**2)\n",
    "\n",
    "\n",
    "    def backward(self):\n",
    "        self.gradients[self.inputs[0]] = (2 / self.m) * self.diff\n",
    "        self.gradients[self.inputs[1]] = (-2 / self.m) * self.diff\n",
    "\n",
    "              \n",
    "def forward_and_backward(outputnode, graph):\n",
    "    # execute all the forward method of sorted_nodes.\n",
    "\n",
    "    ## In practice, it's common to feed in mutiple data example in each forward pass rather than just 1. Because the examples can be processed in parallel. The number of examples is called batch size.\n",
    "    for n in graph:\n",
    "        n.forward()\n",
    "        ## each node execute forward, get self.value based on the topological sort result.\n",
    "\n",
    "    for n in  graph[::-1]:\n",
    "        n.backward()\n",
    "\n",
    "    #return outputnode.value\n",
    "\n",
    "    ###   v -->  a -->  C\n",
    "    ##    b --> C\n",
    "    ##    b --> v -- a --> C\n",
    "    ##    v --> v ---> a -- > C       \n",
    "        \n",
    "\n",
    "        \n",
    "def topological_sort(feed_dict):\n",
    "    \"\"\"\n",
    "    Sort generic nodes in topological order using Kahn's Algorithm.\n",
    "    `feed_dict`: A dictionary where the key is a `Input` node and the value is the respective value feed to that node.\n",
    "    Returns a list of sorted nodes.\n",
    "    \"\"\"\n",
    "\n",
    "    input_nodes = [n for n in feed_dict.keys()]\n",
    "\n",
    "    G = {}\n",
    "    nodes = [n for n in input_nodes]\n",
    "    while len(nodes) > 0:\n",
    "        n = nodes.pop(0)\n",
    "        if n not in G:\n",
    "            G[n] = {'in': set(), 'out': set()}\n",
    "        for m in n.outputs:\n",
    "            if m not in G:\n",
    "                G[m] = {'in': set(), 'out': set()}\n",
    "            G[n]['out'].add(m)\n",
    "            G[m]['in'].add(n)\n",
    "            nodes.append(m)\n",
    "\n",
    "    L = []\n",
    "    S = set(input_nodes)\n",
    "    while len(S) > 0:\n",
    "        n = S.pop()\n",
    "\n",
    "        if isinstance(n, Input):\n",
    "            n.value = feed_dict[n]\n",
    "            ## if n is Input Node, set n'value as \n",
    "            ## feed_dict[n]\n",
    "            ## else, n's value is caculate as its\n",
    "            ## inbounds\n",
    "            \n",
    "        L.append(n)\n",
    "        for m in n.outputs:\n",
    "            G[n]['out'].remove(m)\n",
    "            G[m]['in'].remove(n)\n",
    "            # if no other incoming edges add to S\n",
    "            if len(G[m]['in']) == 0:\n",
    "                S.add(m)\n",
    "    return L\n",
    "\n",
    "\n",
    "\n",
    "def sgd_update(trainables, learning_rate=1e-2):\n",
    "    # there are so many other update / optimization methods\n",
    "    # such as Adam, Mom, \n",
    "    for t in trainables:\n",
    "        t.value += -1 * learning_rate * t.gradients[t]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据（boston房价预测）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练（测试我们手动实现的神经网络）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples = 506\n",
      "Epoch: 1, Loss: 163.944\n",
      "Epoch: 101, Loss: 9.201\n",
      "Epoch: 201, Loss: 6.438\n",
      "Epoch: 301, Loss: 5.156\n",
      "Epoch: 401, Loss: 5.412\n",
      "Epoch: 501, Loss: 4.614\n",
      "Epoch: 601, Loss: 4.929\n",
      "Epoch: 701, Loss: 4.188\n",
      "Epoch: 801, Loss: 4.626\n",
      "Epoch: 901, Loss: 3.924\n",
      "Epoch: 1001, Loss: 4.642\n",
      "Epoch: 1101, Loss: 3.474\n",
      "Epoch: 1201, Loss: 3.520\n",
      "Epoch: 1301, Loss: 4.492\n",
      "Epoch: 1401, Loss: 3.900\n",
      "Epoch: 1501, Loss: 3.599\n",
      "Epoch: 1601, Loss: 3.817\n",
      "Epoch: 1701, Loss: 3.742\n",
      "Epoch: 1801, Loss: 4.872\n",
      "Epoch: 1901, Loss: 4.444\n",
      "Epoch: 2001, Loss: 4.127\n",
      "Epoch: 2101, Loss: 3.205\n",
      "Epoch: 2201, Loss: 4.122\n",
      "Epoch: 2301, Loss: 4.396\n",
      "Epoch: 2401, Loss: 3.339\n",
      "Epoch: 2501, Loss: 3.572\n",
      "Epoch: 2601, Loss: 3.544\n",
      "Epoch: 2701, Loss: 3.986\n",
      "Epoch: 2801, Loss: 3.878\n",
      "Epoch: 2901, Loss: 3.694\n",
      "Epoch: 3001, Loss: 3.528\n",
      "Epoch: 3101, Loss: 3.440\n",
      "Epoch: 3201, Loss: 4.333\n",
      "Epoch: 3301, Loss: 3.377\n",
      "Epoch: 3401, Loss: 3.931\n",
      "Epoch: 3501, Loss: 4.154\n",
      "Epoch: 3601, Loss: 4.278\n",
      "Epoch: 3701, Loss: 4.077\n",
      "Epoch: 3801, Loss: 4.036\n",
      "Epoch: 3901, Loss: 3.808\n",
      "Epoch: 4001, Loss: 3.576\n",
      "Epoch: 4101, Loss: 3.975\n",
      "Epoch: 4201, Loss: 3.329\n",
      "Epoch: 4301, Loss: 3.452\n",
      "Epoch: 4401, Loss: 2.888\n",
      "Epoch: 4501, Loss: 3.583\n",
      "Epoch: 4601, Loss: 3.633\n",
      "Epoch: 4701, Loss: 3.538\n",
      "Epoch: 4801, Loss: 3.353\n",
      "Epoch: 4901, Loss: 3.507\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "\n",
    "\"\"\"\n",
    "Check out the new network architecture and dataset!\n",
    "Notice that the weights and biases are\n",
    "generated randomly.\n",
    "No need to change anything, but feel free to tweak\n",
    "to test your network, play around with the epochs, batch size, etc!\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.utils import shuffle, resample\n",
    "#from miniflow import *\n",
    "\n",
    "# Load data\n",
    "data = load_boston()\n",
    "X_ = data['data']\n",
    "y_ = data['target']\n",
    "\n",
    "# Normalize data\n",
    "X_ = (X_ - np.mean(X_, axis=0)) / np.std(X_, axis=0)\n",
    "\n",
    "n_features = X_.shape[1]\n",
    "n_hidden = 10\n",
    "W1_ = np.random.randn(n_features, n_hidden)\n",
    "b1_ = np.zeros(n_hidden)\n",
    "W2_ = np.random.randn(n_hidden, 1)\n",
    "b2_ = np.zeros(1)\n",
    "\n",
    "# Neural network\n",
    "X, y = Input(), Input()\n",
    "W1, b1 = Input(), Input()\n",
    "W2, b2 = Input(), Input()\n",
    "\n",
    "l1 = Linear(X, W1, b1)\n",
    "s1 = Sigmoid(l1)\n",
    "l2 = Linear(s1, W2, b2)\n",
    "cost = MSE(y, l2)\n",
    "\n",
    "feed_dict = {\n",
    "    X: X_,\n",
    "    y: y_,\n",
    "    W1: W1_,\n",
    "    b1: b1_,\n",
    "    W2: W2_,\n",
    "    b2: b2_\n",
    "}\n",
    "\n",
    "epochs = 5000\n",
    "# Total number of examples\n",
    "m = X_.shape[0]\n",
    "batch_size = 16\n",
    "steps_per_epoch = m // batch_size\n",
    "\n",
    "graph = topological_sort(feed_dict)\n",
    "trainables = [W1, b1, W2, b2]\n",
    "\n",
    "print(\"Total number of examples = {}\".format(m))\n",
    "\n",
    "# Step 4\n",
    "for i in range(epochs):\n",
    "    loss = 0\n",
    "    for j in range(steps_per_epoch):\n",
    "        # Step 1\n",
    "        # Randomly sample a batch of examples\n",
    "        X_batch, y_batch = resample(X_, y_, n_samples=batch_size)\n",
    "\n",
    "        # Reset value of X and y Inputs\n",
    "        X.value = X_batch\n",
    "        y.value = y_batch\n",
    "\n",
    "        # Step 2\n",
    "        _ = None\n",
    "        forward_and_backward(_, graph) # set output node not important.\n",
    "\n",
    "        # Step 3\n",
    "        rate = 1e-2\n",
    "    \n",
    "        sgd_update(trainables, rate)\n",
    "\n",
    "        loss += graph[-1].value\n",
    "    \n",
    "    if i % 100 == 0: \n",
    "        print(\"Epoch: {}, Loss: {:.3f}\".format(i+1, loss/steps_per_epoch))\n",
    "        losses.append(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x291ef46da58>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(losses)), losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.84530409],\n",
       "       [ 8.48047187],\n",
       "       [ 6.04228649],\n",
       "       [ 6.78951195],\n",
       "       [ 6.00375867],\n",
       "       [ 5.06758624],\n",
       "       [11.12148583],\n",
       "       [ 5.47956418],\n",
       "       [ 5.13101622],\n",
       "       [ 6.50156088]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W2.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.320e-03, 1.800e+01, 2.310e+00, 0.000e+00, 5.380e-01, 6.575e+00,\n",
       "       6.520e+01, 4.090e+00, 1.000e+00, 2.960e+02, 1.530e+01, 3.969e+02,\n",
       "       4.980e+00])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ = data['data']\n",
    "X_[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras 使用实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-10ff18024726>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconv_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# Globally-importable utils.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoves\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;32melif\u001b[0m \u001b[0m_BACKEND\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tensorflow'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Using TensorFlow backend.\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtensorflow_backend\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;31m# Try and load external backend.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframework\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mops\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmoving_averages\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=64, activation='sigmoid', input_dim=13))\n",
    "model.add(Dense(units=30, activation='sigmoid', input_dim=64))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer='sgd',\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_, y_, epochs=5000, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
